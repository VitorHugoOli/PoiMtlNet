{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "RQUrs908JwZP",
    "Ogy1r9kkI39n",
    "6bU0q-AQItx4",
    "0BqM9bVMPo3P",
    "a-ypHX4BPrIC",
    "8ncjzcqcPs5F",
    "6y1Ex-DMPvSa",
    "adEWOCkqORx0",
    "UgeKISxYMs-_"
   ],
   "gpuType": "T4",
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### **Bibliotecas**"
   ],
   "metadata": {
    "id": "RQUrs908JwZP"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eg8yp0O94_h_"
   },
   "source": [
    "from os import mkdir\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Gerando os embeddings gerais com hmrm**"
   ],
   "metadata": {
    "id": "cK2Yf48gJshI"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "T0exkMtlnzZc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "jCP5AQMWq4Y3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### alabama"
   ],
   "metadata": {
    "id": "0BqM9bVMPo3P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# alabama\n",
    "_ = embeddings_job('alabama', path_alabama, weight=0.1, K=7, embedding_size=50)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "lE45u3OPNPrJ",
    "outputId": "eefc5b94-4407-4775-e438-c32ac60ae0c2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### arizona"
   ],
   "metadata": {
    "id": "a-ypHX4BPrIC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# arizona\n",
    "_ = embeddings_job('arizona', path_arizona, weight=0.1, K=7, embedding_size=50)"
   ],
   "metadata": {
    "id": "qRPl06hnI2Lt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "outputId": "9bbc6afd-ad29-4b0d-a436-c5e1c1739291"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### virginia"
   ],
   "metadata": {
    "id": "8ncjzcqcPs5F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# viriginia\n",
    "_ = embeddings_job('virginia', path_virginia, weight=0.1, K=7, embedding_size=50)"
   ],
   "metadata": {
    "id": "c3NvLTU5Xga9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "outputId": "e316ed9c-da53-4fa2-e883-436bf379265e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### chicago"
   ],
   "metadata": {
    "id": "6y1Ex-DMPvSa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# chicago\n",
    "_ = embeddings_job('chicago', path_chicago, weight=0.1, K=7, embedding_size=50)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYImej4IsP7v",
    "outputId": "ec12d91b-bf52-4e2d-e6ea-d152d21877fd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### georgia"
   ],
   "metadata": {
    "id": "adEWOCkqORx0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# georgia\n",
    "_ = embeddings_job('georgia', path_georgia, weight=0.1, K=7, embedding_size=50)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFiTrL8qOWwr",
    "outputId": "9a0538a4-0d68-439d-fe00-6b4ffd38970e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_ = embeddings_job('texas', path_texas, weight=0.1, K=7, embedding_size=50)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **SVM**"
   ],
   "metadata": {
    "id": "UgeKISxYMs-_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# validação cruzada k-fold no modelo\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "split = kf.split(features_alabama.iloc[:, 0:99], features_alabama.iloc[:, 100])\n",
    "fscores, precisions, recalls = [], [], []\n",
    "\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "w_avg_f = []\n",
    "m_avg_f = []\n",
    "\n",
    "w_avg_p = []\n",
    "m_avg_p = []\n",
    "\n",
    "w_avg_r = []\n",
    "m_avg_r = []\n",
    "\n",
    "for train_index, test_index in split:\n",
    "    X_train, Y_train = features_alabama.loc[train_index].iloc[:,\n",
    "                       :99], features_alabama.loc[train_index].iloc[:, 100]\n",
    "    x_test, y_test = features_alabama.loc[test_index].iloc[:,\n",
    "                     :99], features_alabama.loc[test_index].iloc[:, 100]\n",
    "\n",
    "    model = svm.SVC(\n",
    "        kernel=\"linear\", decision_function_shape='ovo', class_weight=\"balanced\")\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    y_predicted = model.predict(x_test)\n",
    "\n",
    "    precision, recall, fscore, support = score(y_test, y_predicted)\n",
    "    acc.append(accuracy_score(y_test, y_predicted))\n",
    "\n",
    "    fscores.append(fscore)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "    w_avg_f.append(f1_score(y_test, y_predicted, average='weighted'))\n",
    "    m_avg_f.append(f1_score(y_test, y_predicted, average='macro'))\n",
    "\n",
    "    w_avg_p.append(precision_score(\n",
    "        y_test, y_predicted, average='weighted'))\n",
    "    m_avg_p.append(precision_score(y_test, y_predicted, average='macro'))\n",
    "\n",
    "    w_avg_r.append(recall_score(y_test, y_predicted, average='weighted'))\n",
    "    m_avg_r.append(recall_score(y_test, y_predicted, average='macro'))\n",
    "    class_labels = sorted(set(y_test))"
   ],
   "metadata": {
    "id": "xL3EvR5LV7y3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "name_columns = [x for x in class_labels]\n",
    "metrics_f = pd.DataFrame(fscores, columns=name_columns)\n",
    "metrics_p = pd.DataFrame(precisions, columns=name_columns)\n",
    "metrics_r = pd.DataFrame(recalls, columns=name_columns)\n",
    "\n",
    "metrics_f[\"accuracy\"] = acc\n",
    "metrics_f[\"macro avg\"] = m_avg_f\n",
    "metrics_f[\"weighted avg\"] = w_avg_f\n",
    "\n",
    "metrics_p[\"weighted avg\"] = w_avg_p\n",
    "metrics_p[\"macro avg\"] = m_avg_p\n",
    "\n",
    "metrics_r[\"weighted avg\"] = w_avg_r\n",
    "metrics_r[\"macro avg\"] = m_avg_r\n",
    "\n",
    "print(\"\\nMétricas precision:\")\n",
    "display(metrics_p)\n",
    "\n",
    "print(\"\\n\\nMétricas recall:\")\n",
    "display(metrics_r)\n",
    "\n",
    "print(\"\\n\\nMétricas fscore:\")\n",
    "display(metrics_f)"
   ],
   "metadata": {
    "id": "ujjTiMN6Wok9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "melted_metrics_f = metrics_f[[0, 1, 2, 3, 4, 5, 6]].melt()\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(melted_metrics_f[\"variable\"].unique()))\n",
    "\n",
    "sns.boxplot(x=\"variable\", y=\"value\", hue=\"variable\", data=melted_metrics_f, palette=palette)\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.title(\"Performance Metrics by Fold\")\n",
    "plt.legend(title=\"Fold\", loc=\"upper right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "TUsMjjpnW8An"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analisando as métricas, podemos concluir que o desempenho do modelo na classificação dos POIs com base no embedding gerado pelo HMRM não é muito alto. Isso sugere que o embedding pode não capturar todas as características importantes dos dados de check-in do Alabama, levando a um desempenho relativamente baixo na classificação dos POIs.\n",
    "\n",
    "Porém isso também pode ser por causa da definição dos parâmetros do próprio hmrm, talvez seja bom estudar mais por exemplo o número de componentes latentes (k), peso, tamanho do embedding, etc. **=>** ***se for isso, tenho algumas dúvidas:***\n",
    "\n",
    "***1. faz sentido testar diferentes valores como no exemplo comentado na main? até achar um que dê resultados melhores?***\n",
    "\n",
    "***2. ou esses resultados são satisfatórios já que o MTL \"aprenderia e melhoraria\" as informações?***"
   ],
   "metadata": {
    "id": "zuiwgntJX5LG"
   }
  }
 ]
}
