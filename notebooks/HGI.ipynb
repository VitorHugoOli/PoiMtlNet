{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpdQErH0vV45"
   },
   "source": [
    "## Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R2asmviOunpd"
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "def baixar_shapefile_estado(estado):\n",
    "    base_url = f'https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-{estado}-census-tracts'\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    link_tag = soup.find('a', href=lambda href: href and href.endswith('.zip'))\n",
    "    if not link_tag:\n",
    "        return None\n",
    "    download_url = link_tag['href']\n",
    "    if not download_url.startswith('http'):\n",
    "        download_url = 'https://catalog.data.gov' + download_url\n",
    "    zip_response = requests.get(download_url)\n",
    "    if zip_response.status_code != 200:\n",
    "        return None\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_response.content)) as zip_ref:\n",
    "        zip_ref.extractall('/content/')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dpRDd9EX7SzB"
   },
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import io, os\n",
    "drive_service = build(\"drive\", \"v3\")\n",
    "\n",
    "def download_from_folder_by_name(service, folder_id: str, filename: str, dest_path: str):\n",
    "    q = f\"'{folder_id}' in parents and name = '{filename}' and trashed = false\"\n",
    "    res = service.files().list(\n",
    "        q=q,\n",
    "        fields=\"files(id,name,size,mimeType)\",\n",
    "        supportsAllDrives=True,\n",
    "        includeItemsFromAllDrives=True,\n",
    "        pageSize=1,\n",
    "    ).execute()\n",
    "    files = res.get(\"files\", [])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado na pasta {folder_id}: {filename}\")\n",
    "\n",
    "    file_id = files[0][\"id\"]\n",
    "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "\n",
    "    request = service.files().get_media(fileId=file_id, supportsAllDrives=True)\n",
    "    with open(dest_path, \"wb\") as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "    return dest_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KUXNzmQKMYP"
   },
   "source": [
    "# Georgia\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-alabama-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SoLFVy73KMYP"
   },
   "source": [
    "ESTADO = \"Georgia\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jiSu94NiKMYP"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9ncgEmsfKMYQ"
   },
   "source": [
    "baixar_shapefile_estado(\"georgia\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "cS00fG1YKMYQ",
    "outputId": "97fa4e5d-3c6e-48bc-f087-8683e44c9cea"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "oErhAYDEKMYQ",
    "outputId": "6529e7ba-689e-474c-e28d-a8dea7802020"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1P1v9xeKMYQ",
    "outputId": "7a47dcd7-118f-4e9e-d25d-2f4e8688d6a3"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "W6zBXy9eKMYQ",
    "outputId": "f66e9543-fa95-43fe-af90-2a740570bad9"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amLJMcS2KMYQ",
    "outputId": "064b8265-3c76-42a4-f80d-4d9d20b534a4"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JPcJ2WvvKMYR"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "loEVj4ePKMYR"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7oOmfLAKMYR",
    "outputId": "c76b9a8c-c0b2-41f1-fb36-d51921a3f2e6"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmCRdcQ9KMYR"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPk2F6jAKMYR",
    "outputId": "4064a675-5108-4900-e449-b8c13cc095b8"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjM0ST7pKMYR",
    "outputId": "0184d6a3-bee2-460d-e4f0-4e5534308db5"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (\n",
    "    df_raw[[lat_col_raw, lon_col_raw, \"placeid\"]]\n",
    "    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"})\n",
    "    .dropna(subset=[\"latitude\", \"longitude\", \"placeid\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "3HVzVvKwKMYS"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Yg8i3rpKMYS"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGf_uzxjKMYS",
    "outputId": "366cc921-d041-4a11-e654-11115f5436ea"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HV1otjHWKMYS",
    "outputId": "71b447e4-be38-457d-a93f-e2829def0646"
   },
   "source": [
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtnzEwccKMYS",
    "outputId": "549b6dd7-7c91-4857-85a5-a9f582911cef"
   },
   "source": [
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({\"in_embed_georgia.weight\": model.clone_input_embedding()}, \"poi-encoder-gowalla-h3_georgia.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb9gumUNqNA6"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OWAng6YBqNA7"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bqJSKcuqNA7",
    "outputId": "da9f409e-026f-4bb4-d42a-e29d31d2c839"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-georgia.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrgUdgVIqNA8",
    "outputId": "c1c76614-6396-445e-da3b-4bfc1aeb0a29"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLx1X0DoqNA8",
    "outputId": "f35e81f3-4f5d-455d-e4fd-89c9fcba28bd"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjCQWKi4qNA8",
    "outputId": "04c35418-cfd4-4994-ac88-b5faa98de9ce"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DeG5UPdlwxo"
   },
   "source": [
    "# Nebraska\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EqBWCZbylwxp"
   },
   "source": [
    "ESTADO = \"Nebraska\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kbVonJ4mlwxp"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_gOtH27nlwxp"
   },
   "source": [
    "baixar_shapefile_estado(\"nebraska\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "iTrXRv35lwxp",
    "outputId": "ab1124a8-0bd4-4abf-9cae-ca68a2ca7b0c"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "NRrwN16Qlwxq",
    "outputId": "86c06a37-5cef-4ea3-a102-fa5ac3ccb35c"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sEmCe-slwxq",
    "outputId": "52f27fe1-710e-42bb-b456-44c2068063bd"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WWlkrV7Dlwxq",
    "outputId": "f4fd1df2-e80b-4734-baac-d213e4fb77a7"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2uJOtbplwxq",
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yRTfZdullwxq"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mI2zlnZRlwxq"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnfnPZUalwxq",
    "outputId": "4c9d94cc-75dc-46e3-efdc-3e49edce0b43"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Ih3Nbtlwxr"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9ZlTmC2lwxr",
    "outputId": "9083f777-c646-46ec-ab10-1251936e2c5b"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3J-cSIPblwxr",
    "outputId": "a4915729-bf15-48ed-a37f-f14546f56f98"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "k2lBmcw4lwxr"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iVy8oNU1lwxr"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6usfGUpolwxr",
    "outputId": "fcc2fb6a-8673-4c9b-916a-cde555aae22d"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZXt5eqWClwxs"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Q6Lvjl_lwxs",
    "outputId": "d73247e8-ac32-4be0-d12b-57ac75f6350c"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1DcB9svlwxs",
    "outputId": "2f909a3a-b8e7-4fd5-d030-c69ab747556c"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({\"in_embed.weight\": model.clone_input_embedding()}, \"poi-encoder-gowalla-h3.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k_05hdXlwxs"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zyDHx43nlwxs"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qidVlGQolwxs",
    "outputId": "efd31daf-507c-42d3-b796-bd06f0c228c9"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIUbLFsZlwxt",
    "outputId": "18f5c595-83e3-432f-9a7f-56de8c2e9183"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwPkTlnvlwxt",
    "outputId": "c1997221-e820-4d03-f485-3762ad07bd4e"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgIpk4PKlwxt",
    "outputId": "178b98be-9742-49ad-c369-c0d06f24d286"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9yblWgMsZlw"
   },
   "source": [
    "# Texas\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-texas-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XxicPOC5sZlx"
   },
   "source": [
    "ESTADO = \"Texas\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9QQt_uNasZlx"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uI_UCLh4sZlx"
   },
   "source": [
    "baixar_shapefile_estado(\"texas\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "_FPHAdxhsZly",
    "outputId": "8eb20003-433f-4349-ab7a-fc134b12e51b"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "IChVws_msZly",
    "outputId": "bba893fb-2414-4133-f36c-d9c621176b52"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egQpjTASsZly",
    "outputId": "3b99a8b9-f1e0-46e2-8a19-e55b3501461e"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Er4TbYnFsZlz",
    "outputId": "41ed98d1-ab6f-459a-be74-233bf2cf6ae5"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HGzqpp4sZlz",
    "outputId": "3f32b6f2-7b94-4706-dc63-f23e2bb87ff2"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zydcVnKbsZl0"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w6n1rMt-sZl0"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-FVZe7dsZl0",
    "outputId": "cbd4e100-c23a-412e-fa32-157f0b54f80a"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4LIdEvKsZl1"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqltxgm5sZl1",
    "outputId": "7d9cd153-5655-40b5-9a62-cd8c0089c72b"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fp1Qb7UJsZl1",
    "outputId": "2d93794b-4aeb-4c30-9887-9ac61f1ff5a9"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (\n",
    "    df_raw[[lat_col_raw, lon_col_raw, \"placeid\"]]\n",
    "    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"})\n",
    "    .dropna(subset=[\"latitude\", \"longitude\", \"placeid\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "tInFftIWsZl2"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kyga-eyrsZl2"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMvxJE62sZl2",
    "outputId": "227a3ce6-df80-4027-f4f0-7aedcf047379"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vv2QBFWWsZl3",
    "outputId": "7578e926-c15e-4a69-d776-af6c275fb367"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SDWGt7DgsZl3"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg1TpDKJsZl3",
    "outputId": "28439fde-338f-49dd-824f-49ba3a296ec1"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUGGRKwZsZl3",
    "outputId": "78f0865d-c15e-4f19-fc45-382dd4d43198"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({\"in_embed_texas.weight\": model.clone_input_embedding()}, \"poi-encoder-gowalla-h3_texas.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XYR7DuzsZl4"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MwyuKu74sZl4"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7531MU7sZl4",
    "outputId": "e8b480ce-372d-4ea2-d159-c0e4ac8c37e5"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-texas.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ir6go3zlsZl4",
    "outputId": "80e2d61a-e4e3-4492-b222-dde9bb1a6c49"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT1xWsmlsZl5",
    "outputId": "3128efba-6c47-4caf-f067-4240d65c8f26"
   },
   "source": [
    "data_dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "Z0D7V6phsZl5",
    "outputId": "c57e3267-057c-48cd-d956-c3154edd79cb"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX4eLWCssZl5",
    "outputId": "b7aca150-cbf4-4e16-bb8b-ee20458e7d21"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnB3LvcqtfmL"
   },
   "source": [
    "# California\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-texas-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a54fHTTatfmL"
   },
   "source": [
    "ESTADO = \"California\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3eQoDAgotfmL"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ECXqOGK7tfmL"
   },
   "source": [
    "baixar_shapefile_estado(\"california\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "FXc6AToVtfmL",
    "outputId": "26798da2-78a0-4441-9132-6ea69c4106d5"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "vaK7XTcGtfmM",
    "outputId": "0b0cf86d-c201-497c-f90f-a049fa7dc876"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FghHdJTLtfmM",
    "outputId": "e5680ae0-d9c8-4dd6-b52e-ef03ce46646d"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xVNXNGYqtfmM",
    "outputId": "50264f50-e42d-4e2e-ac05-e2995306ea18"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dSZCHyttfmM",
    "outputId": "cfc85223-384f-4e6c-8962-9e8d9c85da39"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UB1E_qkKtfmM"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m17sAqu4tfmM"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sk8wfBItfmM",
    "outputId": "dd720558-1239-49b0-fac9-1fe779d7ec73"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUyBK3wPtfmN"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMcv6EXttfmN",
    "outputId": "0e00e9c1-2efd-4780-93ea-02c152ecfaa1"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd_JR_T6tfmN",
    "outputId": "1531655d-766e-42e6-dfd1-b8a477143196"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (\n",
    "    df_raw[[lat_col_raw, lon_col_raw, \"placeid\"]]\n",
    "    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"})\n",
    "    .dropna(subset=[\"latitude\", \"longitude\", \"placeid\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "GF8-lvnFtfmN"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A05yPqc6tfmN"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwzzUno0tfmN",
    "outputId": "024e7a4e-f57e-42d3-fe23-1d5f34f14138"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSbMGvU-tfmN",
    "outputId": "9b7c7492-6343-4168-8891-e5cf966f2799"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SjJR_OaYtfmO"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCL1RX2TtfmO",
    "outputId": "b8d3cce4-c18f-4a56-d199-8324c2a3b636"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3uNNjGmtfmO",
    "outputId": "b4298e4b-17ee-4a20-ff66-6f0cf2087b1c"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({\"in_embed_california.weight\": model.clone_input_embedding()}, \"poi-encoder-gowalla-h3_california.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d2w7UtYtfmO"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5jkqzl4JtfmO"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9h9U2hKKtfmO",
    "outputId": "809e682c-6e5e-42d4-e8ce-b8f485f7ace2"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-california.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUT9nmAVtfmO",
    "outputId": "2c6d8452-2a9f-4e54-c145-24a7aef7c218"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pID80T9rtfmP",
    "outputId": "3128efba-6c47-4caf-f067-4240d65c8f26"
   },
   "source": [
    "data_dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "FQFHWHtDtfmP",
    "outputId": "f68bc22e-0fdb-402c-b587-9336e728aaa7"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uDOVLOwtfmP",
    "outputId": "90e945f5-1694-4e73-b582-916848bad615"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qcZ4WJWqtfmP",
    "outputId": "2a9a5e4f-2969-42bf-eaf8-1815efddb54a"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqZZKMTibbTr"
   },
   "source": [
    "# Florida\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-florida-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TbvzsTM3bbTr"
   },
   "source": [
    "ESTADO = \"Florida\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nABhjohgbbTs"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M8OpS-n2bbTs"
   },
   "source": [
    "baixar_shapefile_estado(\"florida\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "Uz3QAhtYbbTs",
    "outputId": "f4bc8afc-b085-4883-8a91-7c7ab8062404"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y7AQotUQbbTs"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NdcDeULcbbTt"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-oUyrPOnbbTt"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LNC3LP-7bbTt"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EeTldh5pbbTt"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg7v2k7ZbbTt",
    "outputId": "125c47b0-7039-4484-eae0-a07fd051603b"
   },
   "source": [
    "# @title\n",
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfuntioabbTu",
    "outputId": "2cd2bed1-a692-4d12-a0eb-63191c766703"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pgl1uzNbbbTu",
    "outputId": "028dd7e8-f0da-4c8d-c461-1cde861dc7fb"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbGZJi9vbbTu"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ghDmyr6bbTu",
    "outputId": "1ba0c8b7-8472-48ae-d288-07e5db09ebe9"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xgmw2gdobbTv",
    "outputId": "aae597ad-f407-4927-af77-3ea4d3dd3315"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "coords_raw = (\n",
    "    df_raw[[lat_col_raw, lon_col_raw, \"placeid\"]]\n",
    "    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"})\n",
    "    .dropna(subset=[\"latitude\", \"longitude\", \"placeid\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "coords_raw = (\n",
    "    coords_raw\n",
    "    .groupby(\"placeid\", as_index=True)[[\"latitude\", \"longitude\"]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "        coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QDq3y-lbbTv",
    "outputId": "356da62d-b1ad-47a1-dd9e-ae2c93772f24"
   },
   "source": [
    "pois_out.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "8IqCK2kjbbTv"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xGY58kVPbbTv"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mg-w_J4RbbTv",
    "outputId": "ee5bf41c-ad1a-4b5e-d3fd-a7687f1c3f0b"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UE9osE7qbbTw"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "buJr1JO9bbTw"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ss5ZuFrpbbTw",
    "outputId": "ac8aa059-7969-4138-9ff3-dc0f995fe986"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCSHCHlWbbTw",
    "outputId": "7c5e7c40-69eb-4722-d5eb-cf3b8915d267"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=256,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO.lower()}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO.lower()}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLPvqzydbbTw"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a9f0cgSxbbTx"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "8m2TWJswbbTx",
    "outputId": "af39abb7-e8c5-4b4e-cc9e-176d9e46aa2b"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-{ESTADO.lower()}.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bkkst2PHbbTx",
    "outputId": "6bc93e06-ec6d-4d4f-fdd6-8e8fdecc4d69"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-UiH8KWbbTx",
    "outputId": "870331d2-48e7-4718-b001-630146dd7ba4"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nViT02chbbTx",
    "outputId": "1b15fe3c-8747-4867-8c51-1837de5f24af"
   },
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HGjU8aJbbTy",
    "outputId": "48085fe2-a944-417e-c1c8-a315d8c2cd58"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 500 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1hJD4TebbTy",
    "outputId": "c2f96645-cb42-4105-9cbb-ffc84ea5b893"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 128 --alpha 0.5 --attention_head 4 --epoch 400 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ke086IY0bbTy",
    "outputId": "7299b310-d9de-40c0-fabc-30f25f7618af"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 32 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeyOIjUbLqte"
   },
   "source": [
    "# North Carolina\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-north carolina-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "etlxzff3Lqtf"
   },
   "source": [
    "ESTADO = \"North Carolina\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vxpTHG_ELqtf"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J20SuyKYLqtf"
   },
   "source": [
    "baixar_shapefile_estado(\"north-carolina\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "enwPWZSxLqtg",
    "outputId": "08f78239-365e-44cf-f527-6acf8e0f117c"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "VpZDnAwSLqtg",
    "outputId": "2c824a73-803d-4eed-d082-3e771e412f4e"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOhYE2_ZLqtg",
    "outputId": "6b4d94f9-1949-445d-8795-e099193ef4f8"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9RsQASa2Lqtg",
    "outputId": "29214707-77cd-459f-f925-8e08c099c6a7"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzWakKMVLqtg",
    "outputId": "3f36374b-3176-4f17-9f07-00cf1e03c1d8"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOtJ7m9zLqtg",
    "outputId": "28270188-3f48-4fcc-9a1f-5831134e2c36"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-LE0ih8Lqth",
    "outputId": "125c47b0-7039-4484-eae0-a07fd051603b"
   },
   "source": [
    "# @title\n",
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z0RG8IbWLqth"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ykcp4BQLLqth",
    "outputId": "80060b85-47e1-4a4c-be35-169d953799eb"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgxIDgRcLqth"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_xin4hvLqth",
    "outputId": "6df1c14e-cdd9-426a-c119-4a5178f8b742"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7_kvkKMLqti",
    "outputId": "1ad4024a-a9d0-483f-c373-5134e30904a3"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "coords_raw = (\n",
    "    df_raw[[lat_col_raw, lon_col_raw, \"placeid\"]]\n",
    "    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"})\n",
    "    .dropna(subset=[\"latitude\", \"longitude\", \"placeid\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "coords_raw = (\n",
    "    coords_raw\n",
    "    .groupby(\"placeid\", as_index=True)[[\"latitude\", \"longitude\"]]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "        coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULlF4014Lqti",
    "outputId": "356da62d-b1ad-47a1-dd9e-ae2c93772f24"
   },
   "source": [
    "pois_out.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "UGMRr8NxLqti"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "so3Ye5_JLqti"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4opS_qz5Lqti",
    "outputId": "9fd8ba5a-26fb-46ce-9465-742055881480"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GEaC-nqlLqti"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rzY2tJg5Lqtj"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qO14I2OJLqtj",
    "outputId": "26569bd2-8252-4bd2-ae43-35a26ed8d1d9"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPRDHZBELqtj",
    "outputId": "516d2f1a-69d7-44a3-d1b2-4e9341899bfa"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=256,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO.lower()}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO.lower()}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUBPRC7lLqtj"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wExXhDp3Lqtj"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHjxQMSMLqtk",
    "outputId": "73fb4289-5acc-46b2-8ce0-03dc6f7303bb"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-{ESTADO.lower()}.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0Qbl6PwLqtk",
    "outputId": "1379ad86-c311-43cb-983a-1c587460a1d4"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPU1caHtLqtk",
    "outputId": "870331d2-48e7-4718-b001-630146dd7ba4"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oom2deRlLqtk",
    "outputId": "6ef7eae9-f760-4227-b5f6-4729d2a1c20b"
   },
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWwXL4ICLqtk",
    "outputId": "c380f670-dafd-4a2a-8f0e-d829a5c5897c"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 500 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTCFDYsbLqtl",
    "outputId": "b94a3709-c041-4eeb-a361-855da1fec44c"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 128 --alpha 0.5 --attention_head 4 --epoch 400 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibBxaYQPLqtl",
    "outputId": "7299b310-d9de-40c0-fabc-30f25f7618af"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 32 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMP1zkG1-Kbb"
   },
   "source": [
    "# Florida\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-north florida-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lwjdZh1x-Kbd"
   },
   "source": [
    "ESTADO = \"Florida\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3aQkgg3B-Kbd"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kLw0uuBO-Kbd"
   },
   "source": [
    "baixar_shapefile_estado(\"florida\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "58544983-edcf-424e-fbfa-14ac5b36de09",
    "id": "oUiOY8Iv-Kbd"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "4f0f2cfe-a805-4023-bbf7-2b5e557b2ccf",
    "id": "m_S79CKl-Kbd"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c1b573cb-e2f1-4448-f269-df25cc3665dc",
    "id": "q11-x0pi-Kbe"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "6624408b-410e-4cc1-cb31-2596f1164c9f",
    "id": "aAmaHzgs-Kbe"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "012e517a-77d1-4867-8631-aee8e1e06805",
    "id": "WW3OSHgm-Kbe"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9d4f4124-19ca-40c7-ff8c-be5f8bec3d75",
    "id": "v19-csWT-Kbe"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "125c47b0-7039-4484-eae0-a07fd051603b",
    "id": "XpJlpdlz-Kbe"
   },
   "source": [
    "# @title\n",
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DAfQXXcQ-Kbe"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f72ed08f-b979-40d3-bffd-b68e34f81d61",
    "id": "ABXtsuzx-Kbf"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByjbSi5h-Kbf"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "34f225eb-7bab-41e5-c870-39dc2aaf0590",
    "id": "WEqKQA8B-Kbf"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "cb485e42-6c43-4d82-c1a0-1263ce2e791e",
    "id": "PouN7kea-Kbf"
   },
   "source": [
    "path_sep"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "92635a00-85ec-4493-f5db-f7615d98ca41",
    "id": "mefEoErj-Kbf"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "1d62e461-2a99-4834-fd1d-163d9dabb6fc",
    "id": "DsehvOLS-Kbf"
   },
   "source": [
    "pois_out.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "6sjniT5E-Kbg"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aiobDsst-Kbg"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "001ba0bc-6208-42aa-c9bc-6c8e6516e2ee",
    "id": "FalB_KVY-Kbg"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76bdcfe0-72c8-4062-b5ec-4f79b4f1dfb2",
    "id": "WQF4z5ik-Kbg"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E9R27n4K-Kbg"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "10a40918-0451-4956-d623-3cb341facec9",
    "id": "d-eiWvwx-Kbg"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9a0c5134-99a8-472d-de81-8ac91e88f2a8",
    "id": "85cXvNxL-Kbg"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "loss_history = []\n",
    "\n",
    "for e in range(5):\n",
    "    epoch_loss = 0\n",
    "    batches = 0\n",
    "\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Época {e+1:02d} | Loss média: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO.lower()}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO.lower()}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "ecd80295-dcc2-42db-df47-631cdfb13284",
    "id": "0XfUqftU-Kbh"
   },
   "source": [
    "pd.read_csv(\"pois_gowalla.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxc2qH46-Kbh"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1rad3tOv-Kbh"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "638eb003-2554-42af-f765-5d2dfde6ca22",
    "id": "RYIqWT7O-Kbh"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-{ESTADO.lower()}.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()   # (1224, D)\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "# edge_index -> número total de nós no grafo\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "num_nodes_graph = ei.max() + 1\n",
    "print(\"num_nodes_graph:\", num_nodes_graph)\n",
    "\n",
    "# poi_index.csv tem o mapeamento nó -> placeid\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "print(\"len(poi_index):\", len(order))\n",
    "\n",
    "# X agora tem UM embedding por nó do grafo\n",
    "X = np.zeros((num_nodes_graph, D), dtype=np.float32)\n",
    "\n",
    "# Preenche só os nós que são POIs, usando row_idx\n",
    "missing = 0\n",
    "for row in order.itertuples():\n",
    "    node_idx = int(row.row_idx)          # índice do nó no grafo\n",
    "    pid = row.feature_id                # placeid como string\n",
    "    emb_idx = placeid2idx.get(str(pid))\n",
    "    if emb_idx is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    X[node_idx] = E[emb_idx]\n",
    "\n",
    "print(\"Embeddings dos POIs:\", E.shape)\n",
    "print(\"Matriz X (node embeddings):\", X.shape)\n",
    "print(\"POIs sem embedding encontrado:\", missing)\n",
    "\n",
    "# sanity check\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n",
    "print(\"✅ gowalla.pt salvo com x.shape =\", g.x.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47aec589-cf23-4df5-f8b1-634a93cc2463",
    "id": "2eVa577m-Kbh"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7129068d-247b-468a-852a-f54a118bf3eb",
    "id": "Z1OxqS-_-Kbi"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f4d58f7-70e2-4cd6-a93e-74c5557b4890",
    "id": "IHCnFnoX-Kbi"
   },
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c380f670-dafd-4a2a-8f0e-d829a5c5897c",
    "id": "c0EtIcnv-Kbi"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 500 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "061a49c7-5a73-495b-df0f-e7121d452276",
    "id": "Dnejp37U-Kbi"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 128 --alpha 0.5 --attention_head 4 --epoch 400 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7299b310-d9de-40c0-fabc-30f25f7618af",
    "id": "LAtvZ9dL-Kbi"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 32 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02GcdMH0Cvjq"
   },
   "source": [
    "# California\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-north florida-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ap7lg_6PCvjr"
   },
   "source": [
    "ESTADO = \"California\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pqPk_onPCvjr"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MiRapYqMCvjr"
   },
   "source": [
    "baixar_shapefile_estado(\"california\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "1477c457-8133-49ec-fc0d-a4f9a3fbcbf6",
    "id": "c70ejQLQCvjr"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "56fea632-e4f9-4bc1-91d8-b126141246b9",
    "id": "ccDib8qbCvjr"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1706af7d-5440-4220-898c-73d9ee53061d",
    "id": "2Rcit9lOCvjr"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "0584e5c3-9baa-4819-8207-d906b72b70cc",
    "id": "AY8A7uAxCvjs"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "012e517a-77d1-4867-8631-aee8e1e06805",
    "id": "I8cVNuYKCvjs"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "afd49e2c-d682-44f5-89af-1f2f6fbe8cb4",
    "id": "f5luqVVXCvjs"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "125c47b0-7039-4484-eae0-a07fd051603b",
    "id": "XW0V5RU9Cvjs"
   },
   "source": [
    "# @title\n",
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NzXHIbUZCvjs"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5bb1c40c-746a-49d2-fd70-379eb21c7621",
    "id": "DYxkxTGwCvjs"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSkNOWwlCvjs"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "85571a73-78a4-405b-acd5-f1ee313550ac",
    "id": "YaL3vzZeCvjt"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "cb485e42-6c43-4d82-c1a0-1263ce2e791e",
    "id": "56g6UN09Cvjt"
   },
   "source": [
    "path_sep"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b7ea13f5-0805-4bbc-ba5f-e8c3463c956a",
    "id": "qoW3xXwyCvjt"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "1d62e461-2a99-4834-fd1d-163d9dabb6fc",
    "id": "R9azVFMZCvjt"
   },
   "source": [
    "pois_out.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "cGmVNjr6Cvjt"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y3FXsg3yCvjt"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3a653e7f-d46e-45f3-fbd7-8985528ed2d6",
    "id": "KqwsUubYCvjt"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76bdcfe0-72c8-4062-b5ec-4f79b4f1dfb2",
    "id": "AH8YYU5eCvju"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pjOs6epdCvju"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "689478e5-4f11-4844-f8db-69fb6e25ab36",
    "id": "2HPRX-bSCvju"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b169a98f-707d-4766-f1c2-5308815df38e",
    "id": "B9HS220HCvju"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "loss_history = []\n",
    "\n",
    "for e in range(5):\n",
    "    epoch_loss = 0\n",
    "    batches = 0\n",
    "\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Época {e+1:02d} | Loss média: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO.lower()}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO.lower()}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "ecd80295-dcc2-42db-df47-631cdfb13284",
    "id": "MXRHOvhfCvju"
   },
   "source": [
    "pd.read_csv(\"pois_gowalla.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra1sPPFqCvju"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CbxNVAkJCvjv"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "638eb003-2554-42af-f765-5d2dfde6ca22",
    "id": "oZSPwRTVCvjv"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-{ESTADO.lower()}.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()   # (1224, D)\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "# edge_index -> número total de nós no grafo\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "num_nodes_graph = ei.max() + 1\n",
    "print(\"num_nodes_graph:\", num_nodes_graph)\n",
    "\n",
    "# poi_index.csv tem o mapeamento nó -> placeid\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "print(\"len(poi_index):\", len(order))\n",
    "\n",
    "# X agora tem UM embedding por nó do grafo\n",
    "X = np.zeros((num_nodes_graph, D), dtype=np.float32)\n",
    "\n",
    "# Preenche só os nós que são POIs, usando row_idx\n",
    "missing = 0\n",
    "for row in order.itertuples():\n",
    "    node_idx = int(row.row_idx)          # índice do nó no grafo\n",
    "    pid = row.feature_id                # placeid como string\n",
    "    emb_idx = placeid2idx.get(str(pid))\n",
    "    if emb_idx is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    X[node_idx] = E[emb_idx]\n",
    "\n",
    "print(\"Embeddings dos POIs:\", E.shape)\n",
    "print(\"Matriz X (node embeddings):\", X.shape)\n",
    "print(\"POIs sem embedding encontrado:\", missing)\n",
    "\n",
    "# sanity check\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n",
    "print(\"✅ gowalla.pt salvo com x.shape =\", g.x.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47aec589-cf23-4df5-f8b1-634a93cc2463",
    "id": "FAgW3CmoCvjv"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7129068d-247b-468a-852a-f54a118bf3eb",
    "id": "Xadqhom3Cvjv"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f4d58f7-70e2-4cd6-a93e-74c5557b4890",
    "id": "nIFnYIS1Cvjv"
   },
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c380f670-dafd-4a2a-8f0e-d829a5c5897c",
    "id": "pCY4FvJMCvjw"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 500 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "061a49c7-5a73-495b-df0f-e7121d452276",
    "id": "yPajhSOtCvjw"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 128 --alpha 0.5 --attention_head 4 --epoch 400 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7299b310-d9de-40c0-fabc-30f25f7618af",
    "id": "iILFfMNQCvjw"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 32 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W9UAm-1O9Dl"
   },
   "source": [
    "# Texas\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-north florida-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "clFtZotmO9Dl"
   },
   "source": [
    "ESTADO = \"Texas\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HceuULSFO9Dm"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dVAvP9muO9Dm"
   },
   "source": [
    "baixar_shapefile_estado(\"texas\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "b235a5fc-136d-4b09-ec20-feadc9bc4882",
    "id": "PeXEpB1CO9Dm"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "0f3c15ea-e19d-4600-eb2c-8f2878c23338",
    "id": "y-F2r0Q5O9Dm"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39228e18-c1ea-46a7-910f-3f3917611973",
    "id": "MGPRPt7fO9Dn"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "0584e5c3-9baa-4819-8207-d906b72b70cc",
    "id": "MRZM049mO9Dn"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "012e517a-77d1-4867-8631-aee8e1e06805",
    "id": "ZRlsFTvAO9Dn"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "afd49e2c-d682-44f5-89af-1f2f6fbe8cb4",
    "id": "-aqDeetkO9Dn"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "125c47b0-7039-4484-eae0-a07fd051603b",
    "id": "2olQ1IDXO9Dn"
   },
   "source": [
    "# @title\n",
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CnoosrJqO9Dn"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5bb1c40c-746a-49d2-fd70-379eb21c7621",
    "id": "xvTz5pczO9Do"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFDLY8P2O9Do"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "083f91fa-4538-45d5-e532-8b07a2636f7d",
    "id": "jLD90QwQO9Do"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "cb485e42-6c43-4d82-c1a0-1263ce2e791e",
    "id": "CYqhkJ0vO9Do"
   },
   "source": [
    "path_sep"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1cec1e3d-72dd-492b-8e7a-73d437ac12f2",
    "id": "vnSnQ9dWO9Do"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "outputId": "1d62e461-2a99-4834-fd1d-163d9dabb6fc",
    "id": "xms5aVwlO9Dp"
   },
   "source": [
    "pois_out.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "aeS5-RTTO9Dp"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rc_h6UpjO9Dp"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4abaa457-9517-4144-b57d-33ee792860e6",
    "id": "XIGJkMzWO9Dp"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76bdcfe0-72c8-4062-b5ec-4f79b4f1dfb2",
    "id": "y2Ifb-avO9Dq"
   },
   "source": [
    "test = pd.read_csv(\"pois_gowalla.csv\")\n",
    "len(test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EpgTcT9qO9Dq"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e53240f-4bf3-4885-c86a-d94bc16cba7a",
    "id": "zQlhYhRPO9Dq"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "649eab4f-079e-4d1e-e289-0e1b17f84788",
    "id": "Kg8OkUIsO9Dq"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "loss_history = []\n",
    "\n",
    "for e in range(5):\n",
    "    epoch_loss = 0\n",
    "    batches = 0\n",
    "\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / batches\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f\"Época {e+1:02d} | Loss média: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO.lower()}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO.lower()}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "ecd80295-dcc2-42db-df47-631cdfb13284",
    "id": "04EXVZQEO9Dr"
   },
   "source": [
    "pd.read_csv(\"pois_gowalla.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnHfw3lZO9Dr"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jZEMhA_vO9Dr"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "638eb003-2554-42af-f765-5d2dfde6ca22",
    "id": "7oPtZr7gO9Dr"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_location-{ESTADO.lower()}.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()   # (1224, D)\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "# edge_index -> número total de nós no grafo\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "num_nodes_graph = ei.max() + 1\n",
    "print(\"num_nodes_graph:\", num_nodes_graph)\n",
    "\n",
    "# poi_index.csv tem o mapeamento nó -> placeid\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "print(\"len(poi_index):\", len(order))\n",
    "\n",
    "# X agora tem UM embedding por nó do grafo\n",
    "X = np.zeros((num_nodes_graph, D), dtype=np.float32)\n",
    "\n",
    "# Preenche só os nós que são POIs, usando row_idx\n",
    "missing = 0\n",
    "for row in order.itertuples():\n",
    "    node_idx = int(row.row_idx)          # índice do nó no grafo\n",
    "    pid = row.feature_id                # placeid como string\n",
    "    emb_idx = placeid2idx.get(str(pid))\n",
    "    if emb_idx is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    X[node_idx] = E[emb_idx]\n",
    "\n",
    "print(\"Embeddings dos POIs:\", E.shape)\n",
    "print(\"Matriz X (node embeddings):\", X.shape)\n",
    "print(\"POIs sem embedding encontrado:\", missing)\n",
    "\n",
    "# sanity check\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n",
    "print(\"✅ gowalla.pt salvo com x.shape =\", g.x.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47aec589-cf23-4df5-f8b1-634a93cc2463",
    "id": "Vm0DpzzJO9Ds"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7129068d-247b-468a-852a-f54a118bf3eb",
    "id": "DhpxVKi-O9Ds"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f4d58f7-70e2-4cd6-a93e-74c5557b4890",
    "id": "1Xj98xbxO9Ds"
   },
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c380f670-dafd-4a2a-8f0e-d829a5c5897c",
    "id": "gP786di2O9Ds"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 500 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "061a49c7-5a73-495b-df0f-e7121d452276",
    "id": "KoB63z1nO9Ds"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 128 --alpha 0.5 --attention_head 4 --epoch 400 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7299b310-d9de-40c0-fabc-30f25f7618af",
    "id": "Jb6rsleIO9Dt"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 32 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "TSeq56pP2-pQ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duvnU-ge2--2"
   },
   "source": [
    "# Montana\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hH-Z7Vuv2--2"
   },
   "source": [
    "ESTADO = \"Montana\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H3RAgmg32--2"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "gStPqoxO2--2",
    "outputId": "1833e728-ff55-47fa-bdef-77b9faade628"
   },
   "source": [
    "baixar_shapefile_estado(\"montana\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "outputId": "2636fcdc-327e-419d-9e16-6fedf5a3bf92",
    "id": "ttQsqOEU2--3"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "e4b80896-7bc0-466b-fc13-b515e2166ebc",
    "id": "RHYOiLx-2--3"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d67ce63c-602f-41b1-a8a7-5d7ab31e807b",
    "id": "mMsETkCR2--3"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "f4fd1df2-e80b-4734-baac-d213e4fb77a7",
    "id": "LtVjpT_t2--3"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da",
    "id": "uGuWch6l2--4"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dhTItrF12--4"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wmkjS5gl2--4"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b9c19fd-9966-4b26-f1b1-f361722a85b6",
    "id": "n8CZ-i942--4"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwYoEFHb2--4"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4f2e1bbb-1faa-46e2-c7bf-8e2eec55b56c",
    "id": "Ud0E6CPw2--4"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c24ab22c-470d-49a4-8a86-f9e48d069410",
    "id": "eqR48Wf42--5"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "pzjJqL6x2--5"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BFXUMH6v2--5"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "68494e9c-c266-45af-bc81-6c6988a0deae",
    "id": "w_iKmvOY2--5"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ELNBUNj_2--5"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ecd705c8-a1c2-4c7d-b8a6-496d138f59b1",
    "id": "2q0vpT082--6"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "926565c0-90a4-492c-8490-87eb40cb041a",
    "id": "Y-NEtari2--6"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZ0pvJv-6XnP",
    "outputId": "07a95fee-008c-473e-bfd5-0564ed8eae4a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS4Cx1Z12--6"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pnxx7lwx2--6"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "out_df = pd.read_csv(f\"/content/drive/MyDrive/MTL_POI_Novo/data/output/{ESTADO.lower()}/embeddings-poi-encoder.csv\")\n",
    "out_df = out_df.sort_values(\"placeid\").reset_index(drop=True)\n",
    "\n",
    "placeids = out_df[\"placeid\"].astype(str).tolist()\n",
    "\n",
    "emb_cols = [c for c in out_df.columns if c.isnumeric()]\n",
    "E = out_df[emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "torch.save({\n",
    "    \"embeddings\": torch.from_numpy(E),\n",
    "    \"placeids\": placeids\n",
    "}, f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso!\")\n",
    "print(E.shape, \"embeddings salvos\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0gZUfboe2WD",
    "outputId": "3fbb48f2-ab02-4ce8-a043-056125efdfe8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1a802514-9d67-4e30-ca13-fdae4b14d41b",
    "id": "K_OhGEWB2--6"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "46ac42f9-0932-4b73-d671-1551433f2e8e",
    "id": "qMZ-Fx5E2--7"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "100e9df7-6497-4904-d0fb-c608408f2f0b",
    "id": "G135dwlo2--7"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fae8b71f-c62e-44a2-d06d-6bef89473dea",
    "id": "8_lSaCX82--7"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "NtUKpaqzPO2Y"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8flmgpQPPCJ"
   },
   "source": [
    "# Alabama\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rY0wGmrMPPCK"
   },
   "source": [
    "ESTADO = \"Alabama\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9VQVOZUIPPCK"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PyALG2eCPPCL"
   },
   "source": [
    "baixar_shapefile_estado(\"alabama\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "df1dc496-04d5-4ff7-f2b0-ee68ec976c47",
    "id": "LveAO8gzPPCL"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "3d853868-66da-4595-e875-d87cbf0d9340",
    "id": "Uowq-nhdPPCM"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f5f64d0f-e958-4eaf-a227-b5d12c3ab313",
    "id": "M7g1b5A7PPCM"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "6cab86bd-c162-4d40-aa3c-ea46209dec64",
    "id": "_35AYfnjPPCM"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da",
    "id": "wb5HB48QPPCN"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpjUYnBQPPCN",
    "outputId": "8cdca310-beba-4dd0-a489-028f36054999"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rFXevJ4fPPCN"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1df30128-88dc-4ca2-f54e-a3da681c06e0",
    "id": "mHyEI1bsPPCN"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F72qrnnPPCO"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a89c3757-abe0-4a60-9a66-c0b12086563e",
    "id": "d38xdNoHPPCO"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6d96d05a-f845-4a58-c856-d09384167866",
    "id": "eKae5p7QPPCP"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "48gxjX-FPPCP"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rTRpd3NOPPCP"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "68494e9c-c266-45af-bc81-6c6988a0deae",
    "id": "FgZSb7INPPCP"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DXmeucV-PPCQ"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ecd705c8-a1c2-4c7d-b8a6-496d138f59b1",
    "id": "YvNRZMeDPPCQ"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "926565c0-90a4-492c-8490-87eb40cb041a",
    "id": "k6PDtUYWPPCQ"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "07a95fee-008c-473e-bfd5-0564ed8eae4a",
    "id": "DaihiFzjPPCR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeGhG4eQPPCR"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QcpFSrnuPPCR"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "out_df = pd.read_csv(f\"/content/drive/MyDrive/MTL_POI_Novo/data/output/{ESTADO.lower()}/embeddings-poi-encoder.csv\")\n",
    "out_df = out_df.sort_values(\"placeid\").reset_index(drop=True)\n",
    "\n",
    "placeids = out_df[\"placeid\"].astype(str).tolist()\n",
    "\n",
    "emb_cols = [c for c in out_df.columns if c.isnumeric()]\n",
    "E = out_df[emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "torch.save({\n",
    "    \"embeddings\": torch.from_numpy(E),\n",
    "    \"placeids\": placeids\n",
    "}, f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso!\")\n",
    "print(E.shape, \"embeddings salvos\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b57fa4bf-876b-45e0-ff6d-96f0ce653107",
    "id": "1TkSEBGrPPCR"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "97a55289-b78c-4c78-8097-1aa92c8c1540",
    "id": "npeqaoJBPPCS"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5fbc9dd2-de46-4874-8c54-626fc59bc967",
    "id": "nxXYu57OPPCS"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d9a2dc84-ef07-4ebe-f852-5a0e01b1be32",
    "id": "ksfDZ7xFPPCT"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "170bf973-80f7-4173-a04c-06b4d943e975",
    "id": "VfAA-bg9PPCT"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cpu --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "xzAkN7-GijBU"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajSeSlLqijSS"
   },
   "source": [
    "# Florida\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "28XMohB1ijST"
   },
   "source": [
    "ESTADO = \"Florida\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XOkzEAI8ijST"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jexBJOMPijST"
   },
   "source": [
    "baixar_shapefile_estado(\"florida\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "1b290631-eed1-4b92-a117-e283cd087553",
    "id": "QvwoTpuhijSU"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "8612ad6f-e5c7-4983-9573-c1f66ae2f142",
    "id": "FeNeGL3IijSU"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0b1b4fc9-9ad8-48a1-f8c6-d16bf29fa04a",
    "id": "240K0p18ijSU"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "6cab86bd-c162-4d40-aa3c-ea46209dec64",
    "id": "FxmXUnTxijSV"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da",
    "id": "RNUogy9DijSV"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5af15948-2897-44fa-8b2a-a19eaf09cb8e",
    "id": "FTu2IIIlijSV"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VcGb4eVcijSV"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c03ffe05-97a8-44c3-cfce-efb4fe3e615e",
    "id": "2xAlLoRcijSV"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hEyIULeijSV"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d111f256-d495-4993-8503-0008d0040fd8",
    "id": "G_s7ZLekijSV"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa43ba11-5e88-40b6-ddc3-b597767004d5",
    "id": "s5GQECJsijSW"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "XQhz9GMaijSW"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VV1nYB_iijSW"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eK04Owv-ijSW"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YHZDYGxgijSW"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iTvGWbrRijSW"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "54GCh5P5ijSW"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "07a95fee-008c-473e-bfd5-0564ed8eae4a",
    "id": "nLtbPZhaijSX"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtTd4uPKijSX"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1B1iCK7AijSX"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "out_df = pd.read_csv(f\"/content/drive/MyDrive/MTL_POI_Novo/data/output/{ESTADO.lower()}/embeddings-poi-encoder.csv\")\n",
    "out_df = out_df.sort_values(\"placeid\").reset_index(drop=True)\n",
    "\n",
    "placeids = out_df[\"placeid\"].astype(str).tolist()\n",
    "\n",
    "emb_cols = [c for c in out_df.columns if c.isnumeric()]\n",
    "E = out_df[emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "torch.save({\n",
    "    \"embeddings\": torch.from_numpy(E),\n",
    "    \"placeids\": placeids\n",
    "}, f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso!\")\n",
    "print(E.shape, \"embeddings salvos\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "532876d3-43b2-4df7-ba52-f645600e011d",
    "id": "S6kTqxX7ijSX"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7d3f2263-6bc9-4f1b-fed0-01f2c5bda750",
    "id": "78TIMAb2ijSX"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d05b54d0-2594-4e1b-9931-a531b5a0f3e8",
    "id": "mRDILi5iijSX"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d9a2dc84-ef07-4ebe-f852-5a0e01b1be32",
    "id": "tzuiecsOijSY"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n60SH-dckiQW",
    "outputId": "91a4e816-9c75-4484-f705-05590cb76bb8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c7fe2989-b321-47b4-920a-bad5a8a3a84c",
    "id": "H-kiV0JgijSY"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "mzPTilC8GETG"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QNWDZQNGEm6"
   },
   "source": [
    "# California\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nUbIewi7GEm6"
   },
   "source": [
    "ESTADO = \"California\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tR1LaA50GEm6"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U5BL4ASLGEm6"
   },
   "source": [
    "baixar_shapefile_estado(\"california\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "6c0e00e1-aae3-4152-dba2-e29b66d3bdb5",
    "id": "1OGLN1eGGEm7"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "aaae3026-8768-46f1-87c1-f3ad58684a06",
    "id": "sh-hxQAEGEm7"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "12dbfdcf-a058-415d-91d3-df41c01bf3f9",
    "id": "Zv6XafICGEm7"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "6cab86bd-c162-4d40-aa3c-ea46209dec64",
    "id": "16bEWXheGEm7"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da",
    "id": "iAb2nZuaGEm7"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5af15948-2897-44fa-8b2a-a19eaf09cb8e",
    "id": "Sc_4mpYpGEm7"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p7GjdG7JGEm8"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f93194c7-2967-4d43-9731-0bb065329b59",
    "id": "KqGGvmc6GEm8"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkNcVs55GEm8"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e0dd8a40-4970-43e2-f971-da99f153fce7",
    "id": "6kiFbXmNGEm8"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "44ed9db3-38cd-4886-aa8a-cc63dc605770",
    "id": "ESPW70A5GEm8"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "7IM8ihl4GEm8"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sR7OkH2nGEm9"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vb-qdeqxGEm9"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OzAyYpdQGEm9"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BL_LELFDGEm9"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Kz2ZBZHGEm9"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "07a95fee-008c-473e-bfd5-0564ed8eae4a",
    "id": "HyDIkhocGEm9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bczmgqUMGEm9"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lk6ppYaBGEm9"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "out_df = pd.read_csv(f\"/content/drive/MyDrive/MTL_POI_Novo/data/output/{ESTADO.lower()}/embeddings-poi-encoder.csv\")\n",
    "out_df = out_df.sort_values(\"placeid\").reset_index(drop=True)\n",
    "\n",
    "placeids = out_df[\"placeid\"].astype(str).tolist()\n",
    "\n",
    "emb_cols = [c for c in out_df.columns if c.isnumeric()]\n",
    "E = out_df[emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "torch.save({\n",
    "    \"embeddings\": torch.from_numpy(E),\n",
    "    \"placeids\": placeids\n",
    "}, f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso!\")\n",
    "print(E.shape, \"embeddings salvos\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3a717f9a-125c-47d5-9aa9-ade85678b218",
    "id": "gsuzee5ZGEm-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1a98e532-4f10-4e47-ecef-02bb4151ca93",
    "id": "KbbtrlJ7GEm-"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bb159979-0d47-4b43-9ced-9c38ea2f56b5",
    "id": "TF83Pg5hGEm-"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d9a2dc84-ef07-4ebe-f852-5a0e01b1be32",
    "id": "w0FnRruWGEm-"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "91a4e816-9c75-4484-f705-05590cb76bb8",
    "id": "O2o02y4oGEm-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7e4a7838-546c-4902-d413-f1db1f02b922",
    "id": "dTnf5RfMGEm-"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7nbZfOMcmMs"
   },
   "source": [
    "# Texas\n",
    "\n",
    "\n",
    "Census: https://catalog.data.gov/dataset/tiger-line-shapefile-2021-state-nebraska-census-tracts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fb-LBeEScmMt"
   },
   "source": [
    "ESTADO = \"Texas\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7mPy-w1lcmMt"
   },
   "source": [
    "diretorio_principal = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5tDHID4QcmMt"
   },
   "source": [
    "baixar_shapefile_estado(\"texas\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "outputId": "dc000635-1d3b-4300-b432-e177e273c833",
    "id": "Q0ETU7yycmMt"
   },
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "arquivos = [os.path.join(\"/content\", f) for f in os.listdir(\"/content\") if f.endswith(\".shp\")]\n",
    "arquivo = max(arquivos, key=os.path.getmtime)\n",
    "tl = gpd.read_file(arquivo).to_crs(\"EPSG:4326\")\n",
    "tl.plot(edgecolor=\"black\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "4dc59484-cfea-448f-8750-e93008296008",
    "id": "ee_QdjBPcmMt"
   },
   "source": [
    "tl[[\"GEOID\",\"geometry\"]] ##TODO: Passar arquivo para HGI (CSV)\n",
    "\n",
    "## BORO -> GEOID"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed8418f1-c706-4bc6-e9b5-588001fd8b15",
    "id": "tV0R51KncmMt"
   },
   "source": [
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "\n",
    "boroughs = tl[[\"GEOID\", \"geometry\"]].copy()\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "boroughs.to_csv(f\"{diretorio_principal}/boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "outputId": "6cab86bd-c162-4d40-aa3c-ea46209dec64",
    "id": "ARSn4dsecmMu"
   },
   "source": [
    "boroughs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6063dd7f-e9bb-4b68-87ca-a7d9cc22f9da",
    "id": "Q24Jn4_RcmMu"
   },
   "source": [
    "!rm -rf /usr/local/lib/python3.12/dist-packages/~orch*\n",
    "!pip cache purge\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "00121b60-b4fe-42de-d3e2-4b0035ac86ba",
    "id": "gOhmdm8acmMu"
   },
   "source": [
    "%pip -q install -U pip setuptools wheel\n",
    "%pip -q uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "%pip -q install --no-cache-dir geopandas shapely libpysal h3 h3ronpy pyarrow scipy scikit-learn\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vnxra7fKcmMu"
   },
   "source": [
    "%pip -q install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6dd2d3bd-cf61-44f5-d49e-9544daba9f5b",
    "id": "53V9tsqicmMu"
   },
   "source": [
    "%cd {diretorio_principal}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFDXeat5cmMu"
   },
   "source": [
    "## POI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "831b1ab9-1495-4d9d-fad8-fdd1899c5ceb",
    "id": "nQdn1jPccmMu"
   },
   "source": [
    "FOLDER_ID_CRUS = \"1cV807NNGn4gSDX-7fkJ83rlr0nRo4y89\"\n",
    "FOLDER_ID_SEPARATED = \"1XUWhd59YDe8dSrTb6eZlLvhVcLSGpZ7n\"\n",
    "\n",
    "filename = f\"checkins_{ESTADO}.csv\"\n",
    "\n",
    "path_crus = f\"estados/crus/{filename}\"\n",
    "path_sep  = f\"estados/separated/{filename}\"\n",
    "\n",
    "print(\"Baixando (crus)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_CRUS, filename, path_crus)\n",
    "\n",
    "print(\"Baixando (separated)...\")\n",
    "download_from_folder_by_name(drive_service,FOLDER_ID_SEPARATED, filename, path_sep)\n",
    "\n",
    "print(\"Concluído:\", path_crus, \"e\", path_sep)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8dbf92ce-49fa-4c71-8a0a-f75b772ff0b1",
    "id": "CR6sAShscmMv"
   },
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "CHECKIN_NAO_CRU = f\"estados/crus/checkins_{ESTADO}.csv\"\n",
    "CHECKIN_CRU     = f\"estados/separated/checkins_{ESTADO}.csv\"\n",
    "OUT_POIS        = \"pois_gowalla.csv\"\n",
    "\n",
    "df_labeled = pd.read_csv(CHECKIN_NAO_CRU)\n",
    "df_raw     = pd.read_csv(CHECKIN_CRU)\n",
    "\n",
    "lon_col_raw = \"lng\" if \"lng\" in df_raw.columns else \"longitude\"\n",
    "lat_col_raw = \"lat\" if \"lat\" in df_raw.columns else \"latitude\"\n",
    "lon_col_lab = \"lng\" if \"lng\" in df_labeled.columns else (\"longitude\" if \"longitude\" in df_labeled.columns else None)\n",
    "lat_col_lab = \"lat\" if \"lat\" in df_labeled.columns else (\"latitude\" if \"latitude\" in df_labeled.columns else None)\n",
    "\n",
    "def parse_names(cell):\n",
    "    try:\n",
    "        lst = ast.literal_eval(cell)\n",
    "        if isinstance(lst, list):\n",
    "            return [d.get(\"name\") for d in lst if isinstance(d, dict) and \"name\" in d]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df_raw[\"__cat_names\"] = df_raw[\"spot_categories\"].fillna(\"[]\").apply(parse_names)\n",
    "\n",
    "def first_or_none(lst):\n",
    "    return lst[0] if (isinstance(lst, list) and len(lst) > 0) else None\n",
    "\n",
    "df_raw[\"__fclass_name\"] = df_raw[\"__cat_names\"].apply(first_or_none)\n",
    "\n",
    "fclass_by_place = (df_raw.dropna(subset=[\"__fclass_name\"])\n",
    "                          .groupby(\"placeid\")[\"__fclass_name\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "cat_by_place = (df_labeled.dropna(subset=[\"category\"])\n",
    "                          .groupby(\"placeid\")[\"category\"]\n",
    "                          .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0]))\n",
    "\n",
    "coords_raw = (df_raw.groupby(\"placeid\")[[lat_col_raw, lon_col_raw]]\n",
    "                    .mean()\n",
    "                    .rename(columns={lat_col_raw: \"latitude\", lon_col_raw: \"longitude\"}))\n",
    "\n",
    "if coords_raw.empty and lon_col_lab and lat_col_lab and (lon_col_lab in df_labeled.columns) and (lat_col_lab in df_labeled.columns):\n",
    "    coords_raw = (df_labeled.groupby(\"placeid\")[[lat_col_lab, lon_col_lab]]\n",
    "                           .mean()\n",
    "                           .rename(columns={lat_col_lab: \"latitude\", lon_col_lab: \"longitude\"}))\n",
    "\n",
    "coords_raw = coords_raw.dropna()\n",
    "\n",
    "pois = pd.DataFrame({\"feature_id\": coords_raw.index})\n",
    "pois[\"feature_id\"] = pois[\"feature_id\"].astype(int)\n",
    "\n",
    "pois[\"fclass_name\"]   = fclass_by_place.reindex(pois[\"feature_id\"]).values\n",
    "pois[\"category_name\"] = cat_by_place.reindex(pois[\"feature_id\"]).values\n",
    "\n",
    "pois = pois.dropna(subset=[\"fclass_name\", \"category_name\"]).reset_index(drop=True)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pois,\n",
    "    geometry=gpd.points_from_xy(coords_raw.loc[pois[\"feature_id\"], \"longitude\"].values,\n",
    "                                coords_raw.loc[pois[\"feature_id\"], \"latitude\"].values),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf[\"geometry\"] = gdf.geometry.apply(lambda p: p.wkt)\n",
    "\n",
    "fclass_vocab = {n:i for i,n in enumerate(pd.Series(gdf[\"fclass_name\"]).dropna().unique())}\n",
    "cat_vocab    = {n:i for i,n in enumerate(pd.Series(gdf[\"category_name\"]).dropna().unique())}\n",
    "\n",
    "gdf[\"fclass\"]   = gdf[\"fclass_name\"].map(lambda n: fclass_vocab.get(n, -1)).astype(int)\n",
    "gdf[\"category\"] = gdf[\"category_name\"].map(lambda n: cat_vocab.get(n, -1)).astype(int)\n",
    "\n",
    "gdf = gdf[(gdf[\"fclass\"]>=0) & (gdf[\"category\"]>=0)].reset_index(drop=True)\n",
    "\n",
    "pois_out = gdf[[\"feature_id\", \"category\", \"fclass\", \"geometry\"]].copy()\n",
    "pois_out.to_csv(OUT_POIS, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "1xKSAf5rcmMv"
   },
   "source": [
    "# @title\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "lat_min, lat_max = df[\"latitude\"].min(), df[\"latitude\"].max()\n",
    "lon_min, lon_max = df[\"longitude\"].min(), df[\"longitude\"].max()\n",
    "area = box(lon_min, lat_min, lon_max, lat_max).buffer(0.01)\n",
    "\n",
    "boroughs = gpd.GeoDataFrame(geometry=[area], crs=\"EPSG:4326\")\n",
    "\n",
    "boroughs[\"geometry\"] = boroughs[\"geometry\"].apply(lambda g: g.wkt)\n",
    "boroughs.to_csv(\"boroughs_area.csv\", index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_5xJsWN5cmMv"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/poi-encoder'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FrJ-K5iFcmMv"
   },
   "source": [
    "from POIEmbedding import PreProcess\n",
    "\n",
    "PreProcess(\"pois_gowalla.csv\", \"boroughs_area.csv\", h3=False).run() ##TODO H3 FALSO\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p6jhywqIcmMv"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely import wkt\n",
    "\n",
    "def build_node_features_from_location_encoder(pois_csv_path: str,\n",
    "                                              loc_embed_pt_path: str,\n",
    "                                              placeid_col: str = \"feature_id\"):\n",
    "\n",
    "    df_pois = pd.read_csv(pois_csv_path)\n",
    "    if df_pois[\"geometry\"].dtype == object:\n",
    "        df_pois[\"geometry\"] = df_pois[\"geometry\"].apply(wkt.loads)\n",
    "\n",
    "    blob = torch.load(loc_embed_pt_path, map_location=\"cpu\")\n",
    "    E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "    placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "    placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "\n",
    "    ids = df_pois[placeid_col].astype(str).tolist()\n",
    "    D = E.shape[1]\n",
    "    X = np.zeros((len(ids), D), dtype=np.float32)\n",
    "\n",
    "    for i, pid in enumerate(ids):\n",
    "        idx = placeid2idx.get(pid)\n",
    "        if idx is None:\n",
    "            raise KeyError(f\"placeid {pid} não encontrado em {loc_embed_pt_path}. \"\n",
    "                           f\"\")\n",
    "        X[i] = E[idx]\n",
    "\n",
    "    return X, df_pois\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IXhvtqvBcmMv"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "p = POI2Vec()\n",
    "p.train()\n",
    "p.save_walks()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FO0i1Z84cmMv"
   },
   "source": [
    "# @title\n",
    "from POIEmbedding import POI2Vec\n",
    "from model import POISet, EmbeddingModel\n",
    "import torch, torch.utils.data as tud\n",
    "\n",
    "poi2vec = POI2Vec()\n",
    "poi2vec.read_walks()\n",
    "poi2vec.get_global_second_class_walks()\n",
    "\n",
    "second_class_hierarchy_pairs = list(set([tuple(x) for x in poi2vec.pois[[\"category\",\"fclass\"]].to_numpy()]))\n",
    "dataset = POISet(\n",
    "    poi2vec.second_class_number,\n",
    "    poi2vec.second_class_walks,\n",
    "    poi2vec.global_second_class_walks,\n",
    "    k=5\n",
    ")\n",
    "model = EmbeddingModel(\n",
    "    vocab_size=poi2vec.second_class_number,\n",
    "    embed_size=64,\n",
    "    second_class_hierarchy_pairs=second_class_hierarchy_pairs,\n",
    "    le_lambda=1e-8\n",
    ")\n",
    "\n",
    "loader = tud.DataLoader(dataset, batch_size=2048, shuffle=True)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for e in range(5):\n",
    "    for i,(inp,pos,neg) in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        loss,_ = model(inp.long(), pos.long(), neg.long())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "torch.save({f\"in_embed_{ESTADO}.weight\": model.clone_input_embedding()}, f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"poi-encoder-gowalla-h3_{ESTADO}.tensor\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "07a95fee-008c-473e-bfd5-0564ed8eae4a",
    "id": "9XPjnCIWcmMw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsEtgpHUcmMw"
   },
   "source": [
    "## HGI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QkKnctqOcmMw"
   },
   "source": [
    "import sys\n",
    "module_dir = f'{diretorio_principal}/region-embedding/baselines/HGI/preprocess'\n",
    "\n",
    "sys.path.insert(0, module_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "out_df = pd.read_csv(f\"/content/drive/MyDrive/MTL_POI_Novo/data/output/{ESTADO.lower()}/embeddings-poi-encoder.csv\")\n",
    "out_df = out_df.sort_values(\"placeid\").reset_index(drop=True)\n",
    "\n",
    "placeids = out_df[\"placeid\"].astype(str).tolist()\n",
    "\n",
    "emb_cols = [c for c in out_df.columns if c.isnumeric()]\n",
    "E = out_df[emb_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "torch.save({\n",
    "    \"embeddings\": torch.from_numpy(E),\n",
    "    \"placeids\": placeids\n",
    "}, f\"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\")\n",
    "\n",
    "print(\"Arquivo salvo com sucesso!\")\n",
    "print(E.shape, \"embeddings salvos\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "21ab2d9a-9ddf-49b5-f2ac-8dc99a7d9f0c",
    "id": "CV8ivmWZcmMw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9917cbe0-523e-4c2c-d438-ffb9d4f59871",
    "id": "j1ThXcakcmMw"
   },
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from main import Preprocess\n",
    "\n",
    "POIS = \"pois_gowalla.csv\"\n",
    "REGS = \"boroughs_area.csv\"\n",
    "\n",
    "data_dict = Preprocess(POIS, REGS, emb_filename=None, h3=False).get_data_torch()\n",
    "\n",
    "loc_pt_path = \"/content/drive/MyDrive/region-embedding-benchmark-main/region-embedding-benchmark-main/poi_embeddings_encoder.pt\"\n",
    "blob = torch.load(loc_pt_path, map_location=\"cpu\")\n",
    "E = blob[\"embeddings\"].detach().cpu().numpy()\n",
    "placeids = [str(p) for p in blob[\"placeids\"]]\n",
    "placeid2idx = {pid: i for i, pid in enumerate(placeids)}\n",
    "D = E.shape[1]\n",
    "\n",
    "order = pd.read_csv(\"poi_index.csv\")\n",
    "order[\"feature_id\"] = order[\"feature_id\"].astype(str)\n",
    "\n",
    "X = np.zeros((len(order), D), dtype=np.float32)\n",
    "for i, pid in enumerate(order[\"feature_id\"].tolist()):\n",
    "    idx = placeid2idx.get(pid)\n",
    "    if idx is None:\n",
    "        raise KeyError(f\"placeid {pid} não encontrado em {loc_pt_path}. Gere embeddings para todos os POIs.\")\n",
    "    X[i] = E[idx]\n",
    "\n",
    "import numpy as np\n",
    "ei = np.asarray(data_dict['edge_index'])\n",
    "assert ei.max() < X.shape[0], \"edge_index referencia nó >= len(X) — ordem quebrou\"\n",
    "\n",
    "g = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(data_dict['edge_index'], dtype=torch.long),\n",
    "    edge_weight=torch.tensor(data_dict['edge_weight'], dtype=torch.float32),\n",
    ")\n",
    "g.region_id  = torch.tensor(data_dict['region_id'], dtype=torch.long)\n",
    "g.region_area = torch.tensor(data_dict['region_area'], dtype=torch.float32)\n",
    "g.coarse_region_similarity = torch.tensor(data_dict['coarse_region_similarity'], dtype=torch.float32)\n",
    "g.region_adjacency = torch.tensor(data_dict['region_adjacency'], dtype=torch.long)\n",
    "\n",
    "torch.save(g, \"gowalla.pt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1108cbe2-05f4-4d23-a3ce-6069018fc91c",
    "id": "NNVxFe_McmMw"
   },
   "source": [
    "import os, pickle as pkl, torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "g = torch.load(\"./gowalla.pt\", map_location=\"cpu\")\n",
    "\n",
    "data_dict = {\n",
    "    \"node_features\": g.x.detach().cpu().numpy(),\n",
    "    \"edge_index\": g.edge_index.detach().cpu().numpy(),\n",
    "    \"edge_weight\": g.edge_weight.detach().cpu().numpy(),\n",
    "    \"region_id\": g.region_id.detach().cpu().numpy(),\n",
    "    \"region_area\": g.region_area.detach().cpu().numpy(),\n",
    "    \"coarse_region_similarity\": g.coarse_region_similarity.detach().cpu().numpy(),\n",
    "    \"region_adjacency\": g.region_adjacency.detach().cpu().numpy(),\n",
    "}\n",
    "\n",
    "with open(\"./data/gowalla_hgi_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_dict, f)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d9a2dc84-ef07-4ebe-f852-5a0e01b1be32",
    "id": "lv-UPsmlcmMx"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "R_from_id = int(np.max(data_dict[\"region_id\"])) + 1\n",
    "R_area    = len(data_dict[\"region_area\"])\n",
    "R_adj     = int(data_dict[\"region_adjacency\"].max()) + 1\n",
    "R_sim     = data_dict[\"coarse_region_similarity\"].shape[0]\n",
    "\n",
    "print(\"R from id :\", R_from_id)\n",
    "print(\"R area    :\", R_area)\n",
    "print(\"R adj     :\", R_adj)\n",
    "print(\"R sim     :\", R_sim)\n",
    "\n",
    "assert R_from_id == R_area == R_adj == R_sim, \"Desalinhad\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%pip uninstall -y torch torchvision torchaudio torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib\n",
    "\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --no-cache-dir pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
    "  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c7cbf4aa-a651-4293-f7ac-2fc4e59f4195",
    "id": "VgAd6ILUcmMx"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a53be31-ba5d-4d19-ff02-b313b0d3fa26",
    "id": "EEidiYL-cmMx"
   },
   "source": [
    "!python {diretorio_principal}/region-embedding/baselines/HGI/train.py --city gowalla --dim 64 --alpha 0.5 --attention_head 4 --epoch 300 --device cuda --save_name gowalla_h3\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vpdQErH0vV45",
    "-KUXNzmQKMYP",
    "6DeG5UPdlwxo",
    "g9yblWgMsZlw",
    "e4LIdEvKsZl1",
    "fnB3LvcqtfmL",
    "iqZZKMTibbTr",
    "EeyOIjUbLqte",
    "7lBiwn3Y9QGT"
   ],
   "machine_shape": "hm",
   "toc_visible": true,
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
