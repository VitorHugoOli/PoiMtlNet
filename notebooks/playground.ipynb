{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:11:58.919207Z",
     "start_time": "2025-04-09T16:11:57.130948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from configs.globals import DEVICE\n",
    "from data.create_fold import SuperInputData\n",
    "\n",
    "\n",
    "class WindowClassifierWithTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=100, hidden_dim=64, num_classes=7,\n",
    "                 num_layers=2, nhead=8, dropout=0.1, num_windows=9):\n",
    "        super(WindowClassifierWithTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, num_windows, hidden_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.reduction_layer = nn.Linear(num_windows * num_classes, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = x + self.positional_encoding\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        flattened = logits.reshape(logits.size(0), logits.size(1) * logits.size(2))\n",
    "\n",
    "        final_logits = self.reduction_layer(flattened)  # [batch_size, num_classes]\n",
    "\n",
    "        final_probs = F.softmax(final_logits, dim=-1)  # [batch_size, num_classes]\n",
    "\n",
    "        return final_probs\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample input: batch_size=2, num_windows=9, input_dim=3\n",
    "    sample_input = torch.randn(2, 9, 100)\n",
    "\n",
    "    # Instantiate the classifier\n",
    "    model = WindowClassifierWithTransformer()\n",
    "\n",
    "    # Forward pass through the model\n",
    "    output = model(sample_input)\n",
    "    print(output.shape)  # Expected shape: (2, 9, 7)"
   ],
   "id": "e07699bdb27ade02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/Desktop/mestrado/ingred/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:11:58.945974Z",
     "start_time": "2025-04-09T16:11:58.927878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.randn(32, 9, 100)  # Example input\n",
    "\n",
    "model = WindowClassifierWithTransformer()\n",
    "output = model(x)"
   ],
   "id": "a5624667ed0ca560",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:11:59.111882Z",
     "start_time": "2025-04-09T16:11:59.070162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "# Load a pickle file\n",
    "fold_results = None"
   ],
   "id": "533a858d82759a2c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:12:02.731592Z",
     "start_time": "2025-04-09T16:11:59.121920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('/Users/vitor/Desktop/mestrado/ingred/data/output/florida/pre-processing/folds.pkl', 'rb') as f:\n",
    "    fold_results = pickle.load(f)\n",
    "metrics_history = {}"
   ],
   "id": "3e56d16119af6b3d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-04-09T16:36:42.543640Z",
     "start_time": "2025-04-09T16:12:02.769417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fold_idx, (i_fold, dataloader) in enumerate(fold_results.items()):\n",
    "    dataloader_next = dataloader['next']\n",
    "    fold_metrics = defaultdict(list)\n",
    "\n",
    "    model = WindowClassifierWithTransformer()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=0.01,\n",
    "        epochs=200,\n",
    "        steps_per_epoch=len(dataloader_next.train.dataloader)\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epoch_progress = tqdm(range(200), desc=f\"Fold {fold_idx}\")\n",
    "\n",
    "    for epoch in epoch_progress:\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        train_total = 0\n",
    "\n",
    "        for data_next in dataloader_next.train.dataloader:\n",
    "            x_next = data_next['x'].to(DEVICE, non_blocking=True)\n",
    "            y_next = data_next['y'].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out_a = model(x_next)\n",
    "            loss = criterion(out_a, y_next)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            if DEVICE.type == 'mps':\n",
    "                torch.mps.synchronize()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            _, predicted = torch.max(out_a, 1)\n",
    "            correct = (predicted == y_next).sum().item()\n",
    "            total = y_next.size(0)\n",
    "\n",
    "            train_loss += loss.item() * total\n",
    "            train_acc += correct\n",
    "            train_total += total\n",
    "\n",
    "        epoch_train_loss = train_loss / train_total\n",
    "        epoch_train_acc = train_acc / train_total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data_next in dataloader_next.val.dataloader:\n",
    "                x_next = data_next['x'].to(DEVICE, non_blocking=True)\n",
    "                y_next = data_next['y'].to(DEVICE, non_blocking=True)\n",
    "\n",
    "                out_a = model(x_next)\n",
    "                loss = criterion(out_a, y_next)\n",
    "\n",
    "                _, predicted = torch.max(out_a, 1)\n",
    "                correct = (predicted == y_next).sum().item()\n",
    "                total = y_next.size(0)\n",
    "\n",
    "                val_loss += loss.item() * total\n",
    "                val_acc += correct\n",
    "                val_total += total\n",
    "\n",
    "        epoch_val_loss = val_loss / val_total\n",
    "        epoch_val_acc = val_acc / val_total\n",
    "\n",
    "        fold_metrics['train_loss'].append(epoch_train_loss)\n",
    "        fold_metrics['train_acc'].append(epoch_train_acc)\n",
    "        fold_metrics['val_loss'].append(epoch_val_loss)\n",
    "        fold_metrics['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "        epoch_progress.set_postfix({\n",
    "            'tr_loss': f\"{epoch_train_loss:.4f}\",\n",
    "            'tr_acc': f\"{epoch_train_acc:.4f}\",\n",
    "            'vl_loss': f\"{epoch_val_loss:.4f}\",\n",
    "            'vl_acc': f\"{epoch_val_acc:.4f}\"\n",
    "        })\n",
    "\n",
    "\n",
    "    metrics_history[i_fold] = dict(fold_metrics)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted = []\n",
    "        ground_truth = []\n",
    "        for data_next in dataloader_next.val.dataloader:\n",
    "            x_next = data_next['x'].to(DEVICE, non_blocking=True)\n",
    "            y_next = data_next['y'].to(DEVICE, non_blocking=True)\n",
    "\n",
    "            out_a = model(x_next)\n",
    "\n",
    "            _, pred = torch.max(out_a, 1)\n",
    "            predicted.append(pred.cpu().numpy())\n",
    "            ground_truth.append(y_next.cpu().numpy())\n",
    "\n",
    "        report = classification_report(\n",
    "            np.concatenate(ground_truth),\n",
    "            np.concatenate(predicted),\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(json.dumps(report, indent=4))\n",
    "\n",
    "    print(f\"Fold {fold_idx} - Best Val Acc: {best_val_acc:.4f}\")"
   ],
   "id": "f0c5d9cf58f7949d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/Desktop/mestrado/ingred/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fold 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19f25f9caeb144c797a5b2a303f94715"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/Desktop/mestrado/ingred/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:666: UserWarning: pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 3307.0\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 2243.0\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"precision\": 0.3020695952115248,\n",
      "        \"recall\": 0.8229684908789386,\n",
      "        \"f1-score\": 0.44192949907235624,\n",
      "        \"support\": 7236.0\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 1244.0\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 1941.0\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"precision\": 0.25510204081632654,\n",
      "        \"recall\": 0.0449034575662326,\n",
      "        \"f1-score\": 0.07636502481863307,\n",
      "        \"support\": 6681.0\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"precision\": 0.5676114371332251,\n",
      "        \"recall\": 0.7277093004642228,\n",
      "        \"f1-score\": 0.6377665544332211,\n",
      "        \"support\": 6247.0\n",
      "    },\n",
      "    \"accuracy\": 0.37374995674590816,\n",
      "    \"macro avg\": {\n",
      "        \"precision\": 0.1606832961658681,\n",
      "        \"recall\": 0.22794017841562772,\n",
      "        \"f1-score\": 0.16515158261774435,\n",
      "        \"support\": 28899.0\n",
      "    },\n",
      "    \"weighted avg\": {\n",
      "        \"precision\": 0.2573092831383691,\n",
      "        \"recall\": 0.37374995674590816,\n",
      "        \"f1-score\": 0.26617267904236097,\n",
      "        \"support\": 28899.0\n",
      "    }\n",
      "}\n",
      "Fold 0 - Best Val Acc: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/Desktop/mestrado/ingred/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fold 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6959cc53d364c2daf343485709e433d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitor/Desktop/mestrado/ingred/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:666: UserWarning: pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cfb2406857dc8338"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output.shape",
   "id": "bbc0c88b8201e7a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Cross-Stitch Unit\n",
    "class CrossStitchUnit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossStitchUnit, self).__init__()\n",
    "        # Learnable alpha parameters (initialized to identity)\n",
    "        self.alpha = nn.Parameter(torch.tensor([[0.9, 0.1], [0.1, 0.9]], requires_grad=True))\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        # a and b are features from each task branch\n",
    "        a_out = self.alpha[0, 0] * a + self.alpha[0, 1] * b\n",
    "        b_out = self.alpha[1, 0] * a + self.alpha[1, 1] * b\n",
    "        return a_out, b_out\n",
    "\n",
    "\n",
    "# A simple convolutional block\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(F.relu(self.conv(x)))\n",
    "\n",
    "\n",
    "# Main Multi-Task Network with Cross-Stitch\n",
    "class CrossStitchNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossStitchNet, self).__init__()\n",
    "        # Task-specific initial blocks\n",
    "        self.taskA_conv1 = ConvBlock()\n",
    "        self.taskB_conv1 = ConvBlock()\n",
    "\n",
    "        # Cross-stitch unit after first conv layer\n",
    "        self.cross_stitch = CrossStitchUnit()\n",
    "\n",
    "        # Shared second conv block\n",
    "        self.taskA_conv2 = ConvBlock()\n",
    "        self.taskB_conv2 = ConvBlock()\n",
    "\n",
    "        # Task-specific heads\n",
    "        self.taskA_fc = nn.Linear(16 * 7 * 7, 10)  # For classification\n",
    "        self.taskB_fc = nn.Linear(16 * 7 * 7, 1)  # For regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.taskA_conv1(x)\n",
    "        b = self.taskB_conv1(x)\n",
    "\n",
    "        # Cross-stitch blending\n",
    "        a, b = self.cross_stitch(a, b)\n",
    "\n",
    "        # Continue task-specific paths\n",
    "        a = self.taskA_conv2(a)\n",
    "        b = self.taskB_conv2(b)\n",
    "\n",
    "        # Flatten\n",
    "        a = a.view(a.size(0), -1)\n",
    "        b = b.view(b.size(0), -1)\n",
    "\n",
    "        # Final heads\n",
    "        outA = self.taskA_fc(a)\n",
    "        outB = self.taskB_fc(b)\n",
    "        return outA, outB"
   ],
   "id": "232717a0eadc78e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = torch.randn(32, 1, 28, 28)  # Example input\n",
    "\n",
    "model = CrossStitchNet()\n",
    "output = model(x)"
   ],
   "id": "3095e80c46e1c29d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output.shape",
   "id": "9c65aca2fc68d76d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "79376cba1b317c04",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
