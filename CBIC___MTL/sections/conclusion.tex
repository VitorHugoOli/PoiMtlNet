% Section 4: Conclusion and Future Work
\section{Conclusion and Future Work}
\label{sec:conclusion}

In this paper, we introduced a Multi-Task Learning (MTL) framework employing hard parameter-sharing, task-specific encoders, and FiLM layers to jointly address POI Category Classification and Next-POI Prediction using DGI-based POI embeddings.
%Our investigations revealed that while the proposed models, both single-task and MTL, significantly outperformed the HMRM baseline for POI Category Classification, the Next-POI Prediction task was more competitive against the MHA+PE state-of-the-art.

Essentially, the MTL approach did not consistently demonstrate superior performance over its single-task counterparts and exhibited higher computational demands in terms of convergence time and MFLOPs. These findings underscore that the anticipated benefits of MTL are not universally guaranteed and are highly dependent on task compatibility and architectural design.

The lack of significant improvement from the MTL model prompts an analysis of the potential underlying causes, especially since optimizers like Nash-MTL mitigated overt gradient conflicts. We hypothesize three primary factors contributed to this outcome:
\begin{itemize}
    \item \textbf{Subtle Negative Transfer due to Task Dissimilarity:} Although related, the two tasks possess fundamentally different natures. POI Category Classification is a static task that relies on the intrinsic, context-rich features of a single POI embedding. In contrast, Next-POI Prediction is a dynamic, sequential task that depends on capturing temporal patterns and transitions within a user's trajectory. The shared encoder may have been forced to learn a "compromise" representation that was not specialized enough for either task, thus failing to outperform the focused single-task models.
    \item \textbf{Task Difficulty and Representation Mismatch:} The performance gap between the two tasks (with category classification achieving higher F1-scores) suggests an imbalance in difficulty. The representation learned by the shared layers might have become biased towards the features required for the simpler, static classification task, inadvertently hindering its effectiveness for the more complex sequential prediction task. The shared representation may not have been rich enough to simultaneously encode both semantic properties and sequential dynamics effectively.
    \item \textbf{Architectural Restrictiveness:} Our choice of a hard parameter-sharing architecture, while efficient and strongly regularizing, may have been too restrictive for the tasks. The distinct nature of the tasks might require more flexible computational pathways. A single shared block may be insufficient to learn a representation that benefits both, suggesting that soft-sharing or expert-based models could be more appropriate.
\end{itemize}

These insights contribute to the broader understanding of MTL's practical challenges. Future research will proceed along several directions motivated by these hypotheses. We plan to explore alternative parameter-sharing mechanisms, such as \textbf{soft sharing (e.g., Cross-Stitch Networks) or Mixture-of-Experts (MoE) models}, to test the hypothesis that the hard-sharing architecture was overly restrictive. Furthermore, investigating \textbf{advanced multi-task optimizers and loss-balancing schemes} beyond gradient conflict mitigation could address the task difficulty imbalance. Finally, a deeper analysis of \textbf{task relatedness}, perhaps using techniques to measure feature representation overlap, could help quantify the degree of negative transfer and guide future architectural choices.